{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "from halfhop import HalfHop\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import WikipediaNetwork\n",
    "from torch_geometric.datasets import WebKB\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T17:34:53.893356Z",
     "end_time": "2023-12-17T17:34:53.898349Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementing a GNN and halfhop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loading Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[183, 1703], edge_index=[2, 325], y=[183], train_mask=[183], val_mask=[183], test_mask=[183])\n"
     ]
    }
   ],
   "source": [
    "# Four different datasets\n",
    "CiteSeer_dataset = Planetoid(root='/tmp/CiteSeer', name='CiteSeer')\n",
    "cora_dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
    "chameleon_dataset = WikipediaNetwork(root='/tmp/Chameleon', name='Chameleon')\n",
    "texas_dataset = WebKB(root='/tmp/Texas', name='Texas')\n",
    "\n",
    "# Select one dataset\n",
    "dataset = texas_dataset\n",
    "\n",
    "# Assign data\n",
    "raw_data = dataset[0]\n",
    "\n",
    "# Extract data and information\n",
    "num_node_features = dataset.num_node_features\n",
    "num_classes = dataset.num_classes\n",
    "\n",
    "# Reshape the masks to be 1-dimensional if it is 2-dimensional\n",
    "if len(raw_data.train_mask.shape) == 2:\n",
    "    raw_data.train_mask = raw_data.train_mask[:, 0]\n",
    "    raw_data.val_mask = raw_data.val_mask[:, 0]\n",
    "    raw_data.test_mask = raw_data.test_mask[:, 0]\n",
    "\n",
    "original_data = copy.deepcopy(raw_data)\n",
    "print(original_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T19:43:44.571341Z",
     "end_time": "2023-12-17T19:43:44.621210Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modify graph with Half-Hop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[487, 1703], edge_index=[2, 933], y=[183], train_mask=[183], val_mask=[183], test_mask=[183], slow_node_mask=[487])\n"
     ]
    }
   ],
   "source": [
    "transform = HalfHop(alpha=0.5, p=0.99)\n",
    "data = transform(raw_data)\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T19:43:46.002514Z",
     "end_time": "2023-12-17T19:43:46.012485Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define GNN Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)  # First GCN layer\n",
    "        self.conv2 = GCNConv(16, 32)  # Second GCN layer\n",
    "        self.conv3 = GCNConv(32, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # First layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Second layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T18:08:24.873923Z",
     "end_time": "2023-12-17T18:08:24.877919Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define GAT Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "class GATGNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GATGNN, self).__init__()\n",
    "        self.gat1 = GATConv(num_node_features, 8, heads=8, dropout=0.6)\n",
    "        self.gat2 = GATConv(8 * 8, num_classes, heads=1, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.gat1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.gat2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T18:08:25.393534Z",
     "end_time": "2023-12-17T18:08:25.396526Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define GraphSAGE Mdoel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "class GraphSAGEGNN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GraphSAGEGNN, self).__init__()\n",
    "        self.sage1 = SAGEConv(num_node_features, 16)\n",
    "        self.sage2 = SAGEConv(16, 32)\n",
    "        self.sage3 = SAGEConv(32, num_classes)  # Output layer\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        # First GraphSAGE layer\n",
    "        x = F.relu(self.sage1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Second GraphSAGE layer\n",
    "        x = F.relu(self.sage2(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.sage3(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T18:08:26.715994Z",
     "end_time": "2023-12-17T18:08:26.719984Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "outputs": [],
   "source": [
    "# Detect cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Change the model_to_use to select a different model\n",
    "model_to_use = GNN # Select among: GNN, GATGNN, GraphSAGEGNN\n",
    "model = model_to_use(num_node_features, num_classes)\n",
    "\n",
    "# to cuda\n",
    "model.to(device)\n",
    "data = data.to(device)\n",
    "original_data = original_data.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)  # Learning rate can be adjusted\n",
    "\n",
    "# Training loop\n",
    "def training(num_iter, origin=False):\n",
    "    for epoch in range(num_iter):  # Number of epochs can be adjusted\n",
    "        model.train()\n",
    "        optimizer.zero_grad()  # Clear existing gradients\n",
    "        if origin:\n",
    "            out = model(original_data)  # Perform a forward pass\n",
    "        else:\n",
    "            out = model(data)  # Perform a forward pass\n",
    "            out = out[~data.slow_node_mask] # Get rid of slow nodes added\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "        loss.backward()  # Perform backpropagation\n",
    "        optimizer.step()  # Update the model's parameters\n",
    "\n",
    "        # Optionally print the loss every few epochs\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T19:43:53.495463Z",
     "end_time": "2023-12-17T19:43:53.503441Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently training: 0 origin: False\n",
      "Epoch 0, Loss: 1.6580770015716553\n",
      "Epoch 50, Loss: 0.35917413234710693\n",
      "Epoch 100, Loss: 0.17813044786453247\n",
      "Epoch 150, Loss: 0.06577899307012558\n",
      "Epoch 200, Loss: 0.09886477142572403\n",
      "Epoch 250, Loss: 0.05726570263504982\n",
      "Accuracy: 0.4594594594594595\n",
      "Currently training: 1 origin: False\n",
      "Epoch 0, Loss: 0.02751295082271099\n",
      "Epoch 50, Loss: 0.025687916204333305\n",
      "Epoch 100, Loss: 0.0572870634496212\n",
      "Epoch 150, Loss: 0.05590810999274254\n",
      "Epoch 200, Loss: 0.14235062897205353\n",
      "Epoch 250, Loss: 0.05857732519507408\n",
      "Accuracy: 0.43243243243243246\n",
      "Currently training: 2 origin: False\n",
      "Epoch 0, Loss: 0.06296152621507645\n",
      "Epoch 50, Loss: 0.1407254934310913\n",
      "Epoch 100, Loss: 0.028070420026779175\n",
      "Epoch 150, Loss: 0.07443662732839584\n",
      "Epoch 200, Loss: 0.12099496275186539\n",
      "Epoch 250, Loss: 0.1065288707613945\n",
      "Accuracy: 0.40540540540540543\n",
      "Currently training: 3 origin: False\n",
      "Epoch 0, Loss: 0.05563979968428612\n",
      "Epoch 50, Loss: 0.11408531665802002\n",
      "Epoch 100, Loss: 0.06674143671989441\n",
      "Epoch 150, Loss: 0.04048297926783562\n",
      "Epoch 200, Loss: 0.012290943413972855\n",
      "Epoch 250, Loss: 0.04194250330328941\n",
      "Accuracy: 0.40540540540540543\n",
      "Currently training: 4 origin: False\n",
      "Epoch 0, Loss: 0.042939234524965286\n",
      "Epoch 50, Loss: 0.061311058700084686\n",
      "Epoch 100, Loss: 0.03128931671380997\n",
      "Epoch 150, Loss: 0.033866990357637405\n",
      "Epoch 200, Loss: 0.06775957345962524\n",
      "Epoch 250, Loss: 0.03721323609352112\n",
      "Accuracy: 0.43243243243243246\n",
      "Currently training: 5 origin: False\n",
      "Epoch 0, Loss: 0.016564859077334404\n",
      "Epoch 50, Loss: 0.019452443346381187\n",
      "Epoch 100, Loss: 0.04947861284017563\n",
      "Epoch 150, Loss: 0.0304360743612051\n",
      "Epoch 200, Loss: 0.101915642619133\n",
      "Epoch 250, Loss: 0.040835581719875336\n",
      "Accuracy: 0.4864864864864865\n",
      "Currently training: 6 origin: False\n",
      "Epoch 0, Loss: 0.0400579497218132\n",
      "Epoch 50, Loss: 0.07565221190452576\n",
      "Epoch 100, Loss: 0.0019927204120904207\n",
      "Epoch 150, Loss: 0.006597992964088917\n",
      "Epoch 200, Loss: 0.02403939701616764\n",
      "Epoch 250, Loss: 0.06439894437789917\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 7 origin: False\n",
      "Epoch 0, Loss: 0.04121816158294678\n",
      "Epoch 50, Loss: 0.03645770251750946\n",
      "Epoch 100, Loss: 0.02946149930357933\n",
      "Epoch 150, Loss: 0.04465671628713608\n",
      "Epoch 200, Loss: 0.033858418464660645\n",
      "Epoch 250, Loss: 0.019714070484042168\n",
      "Accuracy: 0.43243243243243246\n",
      "Currently training: 8 origin: False\n",
      "Epoch 0, Loss: 0.03622982278466225\n",
      "Epoch 50, Loss: 0.11120536178350449\n",
      "Epoch 100, Loss: 0.01732429303228855\n",
      "Epoch 150, Loss: 0.021929053589701653\n",
      "Epoch 200, Loss: 0.015908481553196907\n",
      "Epoch 250, Loss: 0.053713358938694\n",
      "Accuracy: 0.4594594594594595\n",
      "Currently training: 9 origin: False\n",
      "Epoch 0, Loss: 0.01937885396182537\n",
      "Epoch 50, Loss: 0.05073738470673561\n",
      "Epoch 100, Loss: 0.07034905254840851\n",
      "Epoch 150, Loss: 0.029965249821543694\n",
      "Epoch 200, Loss: 0.008714491501450539\n",
      "Epoch 250, Loss: 0.0793319046497345\n",
      "Accuracy: 0.43243243243243246\n",
      "Currently training: 10 origin: False\n",
      "Epoch 0, Loss: 0.11629439890384674\n",
      "Epoch 50, Loss: 0.08531255275011063\n",
      "Epoch 100, Loss: 0.024646658450365067\n",
      "Epoch 150, Loss: 0.00115127710159868\n",
      "Epoch 200, Loss: 0.06652448326349258\n",
      "Epoch 250, Loss: 0.044058382511138916\n",
      "Accuracy: 0.43243243243243246\n",
      "Currently training: 11 origin: False\n",
      "Epoch 0, Loss: 0.04961347207427025\n",
      "Epoch 50, Loss: 0.05618444085121155\n",
      "Epoch 100, Loss: 0.054208386689424515\n",
      "Epoch 150, Loss: 0.032448314130306244\n",
      "Epoch 200, Loss: 0.18588295578956604\n",
      "Epoch 250, Loss: 0.011361196637153625\n",
      "Accuracy: 0.4594594594594595\n",
      "Currently training: 12 origin: False\n",
      "Epoch 0, Loss: 0.06792635470628738\n",
      "Epoch 50, Loss: 0.0005291476263664663\n",
      "Epoch 100, Loss: 0.05689157918095589\n",
      "Epoch 150, Loss: 0.00931625533849001\n",
      "Epoch 200, Loss: 0.037151142954826355\n",
      "Epoch 250, Loss: 0.06719236075878143\n",
      "Accuracy: 0.43243243243243246\n",
      "Currently training: 13 origin: False\n",
      "Epoch 0, Loss: 0.06488435715436935\n",
      "Epoch 50, Loss: 0.025742072612047195\n",
      "Epoch 100, Loss: 0.004819775931537151\n",
      "Epoch 150, Loss: 0.014637034386396408\n",
      "Epoch 200, Loss: 0.014607888646423817\n",
      "Epoch 250, Loss: 0.002892441349104047\n",
      "Accuracy: 0.43243243243243246\n",
      "Currently training: 14 origin: False\n",
      "Epoch 0, Loss: 0.03303326666355133\n",
      "Epoch 50, Loss: 0.03383327275514603\n",
      "Epoch 100, Loss: 0.013748877681791782\n",
      "Epoch 150, Loss: 0.04089788720011711\n",
      "Epoch 200, Loss: 0.0033091239165514708\n",
      "Epoch 250, Loss: 0.008117950521409512\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 15 origin: False\n",
      "Epoch 0, Loss: 0.012733733281493187\n",
      "Epoch 50, Loss: 0.037725742906332016\n",
      "Epoch 100, Loss: 0.04666564613580704\n",
      "Epoch 150, Loss: 0.00446545984596014\n",
      "Epoch 200, Loss: 0.12990982830524445\n",
      "Epoch 250, Loss: 0.0026004104875028133\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 16 origin: False\n",
      "Epoch 0, Loss: 0.04043219983577728\n",
      "Epoch 50, Loss: 0.012330858036875725\n",
      "Epoch 100, Loss: 0.01955704391002655\n",
      "Epoch 150, Loss: 0.0214415043592453\n",
      "Epoch 200, Loss: 0.013254540041089058\n",
      "Epoch 250, Loss: 0.031912922859191895\n",
      "Accuracy: 0.40540540540540543\n",
      "Currently training: 17 origin: False\n",
      "Epoch 0, Loss: 0.06961672008037567\n",
      "Epoch 50, Loss: 0.04491010680794716\n",
      "Epoch 100, Loss: 0.011143849231302738\n",
      "Epoch 150, Loss: 0.22007812559604645\n",
      "Epoch 200, Loss: 0.045042604207992554\n",
      "Epoch 250, Loss: 0.015644285827875137\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 18 origin: False\n",
      "Epoch 0, Loss: 0.062265533953905106\n",
      "Epoch 50, Loss: 0.0554778017103672\n",
      "Epoch 100, Loss: 0.0655970573425293\n",
      "Epoch 150, Loss: 0.024891052395105362\n",
      "Epoch 200, Loss: 0.02152395062148571\n",
      "Epoch 250, Loss: 0.05845480412244797\n",
      "Accuracy: 0.43243243243243246\n",
      "Currently training: 19 origin: False\n",
      "Epoch 0, Loss: 0.002053074073046446\n",
      "Epoch 50, Loss: 0.00377463991753757\n",
      "Epoch 100, Loss: 0.011830191127955914\n",
      "Epoch 150, Loss: 0.018038950860500336\n",
      "Epoch 200, Loss: 0.08222601562738419\n",
      "Epoch 250, Loss: 0.049196768552064896\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 0 origin: True\n",
      "Epoch 0, Loss: 15.341620445251465\n",
      "Epoch 50, Loss: 0.47375375032424927\n",
      "Epoch 100, Loss: 0.4576251208782196\n",
      "Epoch 150, Loss: 0.3856889605522156\n",
      "Epoch 200, Loss: 0.33618080615997314\n",
      "Epoch 250, Loss: 0.39252227544784546\n",
      "Accuracy: 0.40540540540540543\n",
      "Currently training: 1 origin: True\n",
      "Epoch 0, Loss: 0.41687363386154175\n",
      "Epoch 50, Loss: 0.33940908312797546\n",
      "Epoch 100, Loss: 0.3818644881248474\n",
      "Epoch 150, Loss: 0.374019056558609\n",
      "Epoch 200, Loss: 0.3038172125816345\n",
      "Epoch 250, Loss: 0.257086843252182\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 2 origin: True\n",
      "Epoch 0, Loss: 0.3638728857040405\n",
      "Epoch 50, Loss: 0.4656321704387665\n",
      "Epoch 100, Loss: 0.2440224587917328\n",
      "Epoch 150, Loss: 0.37960371375083923\n",
      "Epoch 200, Loss: 0.33628714084625244\n",
      "Epoch 250, Loss: 0.3340425193309784\n",
      "Accuracy: 0.40540540540540543\n",
      "Currently training: 3 origin: True\n",
      "Epoch 0, Loss: 0.46684691309928894\n",
      "Epoch 50, Loss: 0.33153244853019714\n",
      "Epoch 100, Loss: 0.24638912081718445\n",
      "Epoch 150, Loss: 0.3551330864429474\n",
      "Epoch 200, Loss: 0.22743360698223114\n",
      "Epoch 250, Loss: 0.2813953459262848\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 4 origin: True\n",
      "Epoch 0, Loss: 0.21777185797691345\n",
      "Epoch 50, Loss: 0.2441154569387436\n",
      "Epoch 100, Loss: 0.29743173718452454\n",
      "Epoch 150, Loss: 0.3099963068962097\n",
      "Epoch 200, Loss: 0.22011373937129974\n",
      "Epoch 250, Loss: 0.31123775243759155\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 5 origin: True\n",
      "Epoch 0, Loss: 0.2400560975074768\n",
      "Epoch 50, Loss: 0.23974744975566864\n",
      "Epoch 100, Loss: 0.3386738896369934\n",
      "Epoch 150, Loss: 0.2951834499835968\n",
      "Epoch 200, Loss: 0.3579428195953369\n",
      "Epoch 250, Loss: 0.276864618062973\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 6 origin: True\n",
      "Epoch 0, Loss: 0.21857866644859314\n",
      "Epoch 50, Loss: 0.3550478219985962\n",
      "Epoch 100, Loss: 0.3040994107723236\n",
      "Epoch 150, Loss: 0.2813270688056946\n",
      "Epoch 200, Loss: 0.29242122173309326\n",
      "Epoch 250, Loss: 0.233429417014122\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 7 origin: True\n",
      "Epoch 0, Loss: 0.26720544695854187\n",
      "Epoch 50, Loss: 0.20057523250579834\n",
      "Epoch 100, Loss: 0.3556213676929474\n",
      "Epoch 150, Loss: 0.38352176547050476\n",
      "Epoch 200, Loss: 0.2390151172876358\n",
      "Epoch 250, Loss: 0.2820017635822296\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 8 origin: True\n",
      "Epoch 0, Loss: 0.22856931388378143\n",
      "Epoch 50, Loss: 0.2518811821937561\n",
      "Epoch 100, Loss: 0.33336734771728516\n",
      "Epoch 150, Loss: 0.35595184564590454\n",
      "Epoch 200, Loss: 0.2319878786802292\n",
      "Epoch 250, Loss: 0.2963525056838989\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 9 origin: True\n",
      "Epoch 0, Loss: 0.199751079082489\n",
      "Epoch 50, Loss: 0.2549057602882385\n",
      "Epoch 100, Loss: 0.24197541177272797\n",
      "Epoch 150, Loss: 0.3197920322418213\n",
      "Epoch 200, Loss: 0.2130976766347885\n",
      "Epoch 250, Loss: 0.20153632760047913\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 10 origin: True\n",
      "Epoch 0, Loss: 0.2656862437725067\n",
      "Epoch 50, Loss: 0.22178156673908234\n",
      "Epoch 100, Loss: 0.1843845695257187\n",
      "Epoch 150, Loss: 0.2401127815246582\n",
      "Epoch 200, Loss: 0.2505110502243042\n",
      "Epoch 250, Loss: 0.33890804648399353\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 11 origin: True\n",
      "Epoch 0, Loss: 0.30836057662963867\n",
      "Epoch 50, Loss: 0.5742565989494324\n",
      "Epoch 100, Loss: 0.2769571840763092\n",
      "Epoch 150, Loss: 0.24552340805530548\n",
      "Epoch 200, Loss: 0.3129655122756958\n",
      "Epoch 250, Loss: 0.26724493503570557\n",
      "Accuracy: 0.3783783783783784\n",
      "Currently training: 12 origin: True\n",
      "Epoch 0, Loss: 0.24995002150535583\n",
      "Epoch 50, Loss: 0.2517288327217102\n",
      "Epoch 100, Loss: 0.28238919377326965\n",
      "Epoch 150, Loss: 0.23274946212768555\n",
      "Epoch 200, Loss: 0.2744566798210144\n",
      "Epoch 250, Loss: 0.303350031375885\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 13 origin: True\n",
      "Epoch 0, Loss: 0.33577674627304077\n",
      "Epoch 50, Loss: 0.26436135172843933\n",
      "Epoch 100, Loss: 0.23542869091033936\n",
      "Epoch 150, Loss: 0.2276386022567749\n",
      "Epoch 200, Loss: 0.19885826110839844\n",
      "Epoch 250, Loss: 0.319004088640213\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 14 origin: True\n",
      "Epoch 0, Loss: 0.2037934958934784\n",
      "Epoch 50, Loss: 0.24917519092559814\n",
      "Epoch 100, Loss: 0.2625826597213745\n",
      "Epoch 150, Loss: 0.16231554746627808\n",
      "Epoch 200, Loss: 0.28921064734458923\n",
      "Epoch 250, Loss: 0.3556658923625946\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 15 origin: True\n",
      "Epoch 0, Loss: 0.2584065794944763\n",
      "Epoch 50, Loss: 0.22265830636024475\n",
      "Epoch 100, Loss: 0.3205477297306061\n",
      "Epoch 150, Loss: 0.18705010414123535\n",
      "Epoch 200, Loss: 0.19393721222877502\n",
      "Epoch 250, Loss: 0.30471399426460266\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 16 origin: True\n",
      "Epoch 0, Loss: 0.2437281310558319\n",
      "Epoch 50, Loss: 0.23127280175685883\n",
      "Epoch 100, Loss: 0.212820366024971\n",
      "Epoch 150, Loss: 0.2599228620529175\n",
      "Epoch 200, Loss: 0.37610459327697754\n",
      "Epoch 250, Loss: 0.2576133906841278\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 17 origin: True\n",
      "Epoch 0, Loss: 0.2716207504272461\n",
      "Epoch 50, Loss: 0.258493572473526\n",
      "Epoch 100, Loss: 0.3020566999912262\n",
      "Epoch 150, Loss: 0.1780320554971695\n",
      "Epoch 200, Loss: 0.22424660623073578\n",
      "Epoch 250, Loss: 0.2729797661304474\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 18 origin: True\n",
      "Epoch 0, Loss: 0.1539459079504013\n",
      "Epoch 50, Loss: 0.14054450392723083\n",
      "Epoch 100, Loss: 0.2383200079202652\n",
      "Epoch 150, Loss: 0.25578737258911133\n",
      "Epoch 200, Loss: 0.202689066529274\n",
      "Epoch 250, Loss: 0.186557337641716\n",
      "Accuracy: 0.35135135135135137\n",
      "Currently training: 19 origin: True\n",
      "Epoch 0, Loss: 0.2561384439468384\n",
      "Epoch 50, Loss: 0.2887091338634491\n",
      "Epoch 100, Loss: 0.28312769532203674\n",
      "Epoch 150, Loss: 0.35181039571762085\n",
      "Epoch 200, Loss: 0.20267951488494873\n",
      "Epoch 250, Loss: 0.196243554353714\n",
      "Accuracy: 0.32432432432432434\n",
      "Average accuracy without half-hop: 0.36216216216216235\n",
      "Standard deviation without half-hop: 0.019860727644187934\n",
      "Average accuracy with half-hop: 0.4216216216216216\n",
      "Standard deviation with half-hop: 0.03128604568321683\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, origin=False):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        if origin:\n",
    "            out = model(original_data)  # Perform a forward pass\n",
    "        else:\n",
    "            out = model(data)  # Perform a forward pass\n",
    "            out = out[~data.slow_node_mask] # Get rid of slow nodes added\n",
    "        preds = out.argmax(dim=1)  # Get the index of the max log-probability\n",
    "        correct = preds[data.test_mask] == data.y[data.test_mask]\n",
    "        acc = int(correct.sum()) / int(data.test_mask.sum())\n",
    "    return acc\n",
    "\n",
    "# Initialize a list to store accuracies of multiple initialization of model and trainings\n",
    "accuracies = []\n",
    "HH_accuracies = []\n",
    "\n",
    "# Function for multiple times of trainings\n",
    "def multiple_trainings(num_iter, origin=False):\n",
    "    for i in range(num_iter):\n",
    "        print(\"Currently training:\", i, \"origin:\", origin)\n",
    "        if origin:\n",
    "            training(300, True)\n",
    "            accuracy = evaluate(model, True)\n",
    "            accuracies.append(accuracy)\n",
    "        else:\n",
    "            training(300)\n",
    "            accuracy = evaluate(model)\n",
    "            HH_accuracies.append(accuracy)\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# 20 initializations\n",
    "multiple_trainings(20)\n",
    "multiple_trainings(20, True)\n",
    "\n",
    "# Print average accuracy of 20 initializations\n",
    "average_accuracy = sum(accuracies)/len(accuracies)\n",
    "average_accuracy_deviation = (sum([((x - average_accuracy) ** 2) for x in accuracies]) / len(accuracies)) ** 0.5\n",
    "HH_average_accuracy = sum(HH_accuracies)/len(HH_accuracies)\n",
    "HH_average_accuracy_deviation = (sum([((x - HH_average_accuracy) ** 2) for x in HH_accuracies]) / len(HH_accuracies)) ** 0.5\n",
    "print(f'Average accuracy without half-hop: {average_accuracy}')\n",
    "print(f'Standard deviation without half-hop: {average_accuracy_deviation}')\n",
    "print(f'Average accuracy with half-hop: {HH_average_accuracy}')\n",
    "print(f'Standard deviation with half-hop: {HH_average_accuracy_deviation}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-17T19:43:54.650376Z",
     "end_time": "2023-12-17T19:44:38.553900Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
